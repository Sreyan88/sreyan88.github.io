---
layout: page
title: Research
permalink: /research/
order: 5
---
My research focuses on advancing *audio processing*â€”spanning speech, sounds, and music. I aim to tackle challenges such as developing data- and compute-efficient audio models, improving audio representation learning, and improving audio perception and reasoning in AI systems. In my early work, I explored resource-efficient deep learning, devising methods to train models for scenarios constrained by labeled/unlabeled data or compute. This includes synthetic data augmentation, self-supervised learning, etc to enable effective downstream learning.  

Currently, I am working on improving audio perception and reasoning in Large Language Models through better architectures, audio representations, and scalable synthetic data. My publications span diverse tasks within Speech, Language, and Audio Processing, including NLU, room impulse response (RIR) estimation, audio generation, compositional reasoning, Large Audio Language Models (LALMs) and audio captioning.  

I am always open to collaborations, and please feel free to drop me a mail!  

<!-- #### I am always open to collaborations! Please fill out [this](https://docs.google.com/forms/d/1kQRJekonn8YglxIPH9OPcJCuI7NQK-E1wAywNAsSMoM/) form here and I would reach out if I have a project aligned with your interests. Thank You! -->


[Google Scholar](https://scholar.google.com/citations?user=5HKZJHAAAAAJ&hl=en) [Semantic Scholar](https://www.semanticscholar.org/author/Sreyan-Ghosh/3488077)  


### Pre-prints  

* [Deep Clustering for learning general-purpose Audio Representations](https://arxiv.org/pdf/2110.08895.pdf)  
*Sreyan Ghosh*\*, Ashish Seth\*, Sandesh Katta\*, S. Umesh  
[Code](https://github.com/Sreyan88/LAPE)  
**Pre-print**  

* [Analyzing the factors affecting usefulness of Self-Supervised Pre-trained Representations for Speech Recognition](http://arxiv.org/abs/2203.16973)  
Lodagala V S V Durga Prasad\*, Ashish Seth\*, *Sreyan Ghosh*\*, S. Umesh  
**Pre-print**  


### Audio and Spoken Language Processing (Chronological)  

* [Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models](https://arxiv.org/abs/2507.08128)   
Arushi Goel*, *Sreyan Ghosh**, Jaehyeon Kim, Sonal Kumar, Zhifeng Kong, Sang-gil Lee, Chao-Han Huck Yang, Ramani Duraiswami, Dinesh Manocha, Rafael Valle, Bryan Catanzaro        
[Project Page](https://research.nvidia.com/labs/adlr/AF3/) / [Code](https://github.com/NVIDIA/audio-flamingo) / [Demo](https://huggingface.co/spaces/nvidia/audio-flamingo-3) / [Checkpoints and Data](https://huggingface.co/nvidia/audio-flamingo-3) / [Tweet](https://x.com/NVIDIAAIDev/status/1946269274030461143) / [Coverage](https://www.marktechpost.com/2025/07/15/nvidia-just-released-audio-flamingo-3-an-open-source-model-advancing-audio-general-intelligence/)   
**Under Review** 

* [Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities](https://arxiv.org/abs/2410.13198)   
*Sreyan Ghosh*, Zhifeng Kong, Sonal Kumar, S Sakshi, Jaehyeon Kim, Wei Ping, Rafael Valle, Dinesh Manocha, Bryan Catanzaro    
[Project Page](https://research.nvidia.com/labs/adlr/AF2/) / [Code](https://github.com/NVIDIA/audio-flamingo) / [Demo](https://huggingface.co/spaces/nvidia/audio-flamingo-2) / [Tweet](https://x.com/tu7uruu/status/1899558676186452411?s=61) / [Coverage 1](https://artgor.medium.com/paper-review-audio-flamingo-2-an-audio-language-model-with-long-audio-understanding-and-expert-6f34f7b2c07c) / [Coverage 2](https://www.linkedin.com/pulse/audio-flamingo-2-audio-language-model-long-audio-expert-vlad-bogolin-bpble/?trackingId=MiGggYq5SvC%2BAln%2Fsou%2Bag%3D%3D) / [Coverage 3](https://www.cs.umd.edu/article/2025/04/exploring-audio-ai-cs-phd-student-sreyan-ghosh)         
**ICML 2025**    

* [GAMA: A Large Audio-Language Model with Advanced Audio Understanding and Complex Reasoning Abilities](https://arxiv.org/abs/2406.11768)    
*Sreyan Ghosh*\*, Sonal Kumar\*, Ashish Seth, Chandra Kiran Reddy Evuru, Utkarsh Tyagi, S Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha  
[Project Website](https://sreyan88.github.io/gamaaudio/)  / [Slides](https://docs.google.com/presentation/d/1d_vsKmS4sZOS4SfUPp3keqg1fW81CmT3/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true) / [Summary Tweet](https://x.com/SreyanG/status/1803075223992115276) / [Coverage 1](https://www.cs.umd.edu/article/2024/07/umd-researchers-release-gama-llm-advanced-audio-understanding) / [Coverage 2](https://the-vision-debugged.beehiiv.com/p/ep-23-shhh-can-you-hear-that-gama-can)    
**EMNLP 2024** <span style="color:red">**(Oral)**</span>  

* [MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmarks](https://www.arxiv.org/abs/2410.19168)   
S Sakshi\*, Utkarsh Tyagi\*, Sonal Kumar\*, Ashish Seth\*, Ramaneswaran Selvakumar, Oriol Nieto, Ramani Duraiswami, *Sreyan Ghosh*\*, Dinesh Manocha  
[Project Website](https://sakshi113.github.io/mmau_homepage/) / [Slides](https://docs.google.com/presentation/d/13Md5BBDs_z5sNp-JB0Cuf4IRDXPwAZGq/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true) / [Talk](https://drive.google.com/file/d/1BdWmtTv2KvSE7sC-kDdUshX98QMBpgo2/view?usp=sharing)    
**ICLR 2025** <span style="color:red">**(Spotlight)**</span>  

* [*Failing Forward*: Improving Generative Error Correction for ASR with Synthetic Data and Retrieval Augmentation](https://arxiv.org/abs/2410.13198)   
*Sreyan Ghosh*, Mohammad Sadegh Rasooli, Michael Levit, Peidong Wang, Jian Xue, Dinesh Manocha, Jinyu Li  
**ACL 2025 (Findings)**  

* [Synthio: Augmenting Small-Scale Audio Classification Datasets with Synthetic Data](https://arxiv.org/abs/2410.02056)    
*Sreyan Ghosh*,  Sonal Kumar, Zhifeng Kong, Rafael Valle, Bryan Catanzaro, Dinesh Manocha  
[Code](https://github.com/Sreyan88/Synthio) / [Text-to-Audio Demo](https://huggingface.co/spaces/sonalkum/synthio-stable-audio-open) / [Slides](https://docs.google.com/presentation/d/1r_McrwQ1xHsRmEaaWOj_QFYWI9MCPMyL/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true)        
**ICLR 2025**  

* [ReCLAP: Improving Zero Shot Audio Classification by Describing Sounds](https://arxiv.org/abs/2409.09213)    
*Sreyan Ghosh*, Sonal Kumar, Chandra Kiran Reddy Evuru, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha   
[Code](https://github.com/Sreyan88/ReCLAP) / [Slides](https://docs.google.com/presentation/d/19C9tq0J4sEuz0X43HbMTAc_o_6dP1KQi/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true)    
**ICASSP 2025**  <span style="color:red">**(Oral)**</span> 

* [ProSE: Diffusion Priors for Speech Enhancement](https://arxiv.org/abs/2410.15062)   
Sonal Kumar, *Sreyan Ghosh*, Utkarsh Tyagi, Anton Jeran Ratnarajah, Chandra Kiran Reddy Evuru, Ramani Duraiswami, Dinesh Manocha    
[Code](https://github.com/sonalkum/ProSE) / [Slides](https://docs.google.com/presentation/d/1MCuLsWBf5GuLc-sTq--y9Rzq0dVVX48K/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true) / [Talk](https://drive.google.com/file/d/1xS7X0sWvPvpjKsU4fwa8f7zdPHFB2Agd/view?usp=sharing)    
**NAACL 2025**  <span style="color:red">**(Oral)**</span> 

* [PAT: Parameter-Free Audio-Text Aligner to Boost Zero-Shot Audio Classification](https://arxiv.org/abs/2410.15062)   
Ashish Seth, Ramaneswaran Selvakumar, Sonal Kumar, *Sreyan Ghosh*, Dinesh Manocha  
[Code](https://github.com/cs20s030/PAT) / [Talk](https://drive.google.com/file/d/1Zeg7ykWMKUkivYW3cbCssqMPOE7QUxw1/view?usp=sharing) / [Slides](https://docs.google.com/presentation/d/1uNSexf9RxBjsArIly_dUsy7tXdg8b5tg/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true)    
**NAACL 2025**  <span style="color:red">**(Oral)**</span> 

* [Do Audio-Language Models Understand Linguistic Variations?](https://arxiv.org/abs/2410.16505v1)     
Ramaneswaran Selvakumar, Sonal Kumar, Hemant Kumar Giri, Nishit Anand, Ashish Seth, *Sreyan Ghosh*, Dinesh Manocha  
**NAACL 2025**  

* [EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning](https://arxiv.org/abs/2410.13179)   
Ashish Seth\*, Ramaneswaran Selvakumar, S Sakshi, Sonal Kumar, *Sreyan Ghosh*\*, Dinesh Manocha  
[GitHub](https://github.com/cs20s030/ehmam)   
**EMNLP 2024** <span style="color:red">**(Oral)**</span>  

* [LipGER: Visually-Conditioned Generative Error Correction for Robust Automatic Speech Recognition](https://arxiv.org/abs/2406.04432)  
*Sreyan Ghosh*\*, Sonal Kumar, Ashish Seth, Purva Chiniya, Utkarsh Tyagi, Ramani Duraiswami, Dinesh Manocha  
[Code](https://github.com/Sreyan88/LipGER) / [Slides](https://docs.google.com/presentation/d/1ifZ7CMN2pp16artUd_zH48LANp1eQkLd/edit?usp=sharing&ouid=111957209895724121113&rtpof=true&sd=true) / [Talk](https://drive.google.com/file/d/1qZcK-M63QStWiTMgmqu_UZ0qDIdhDUYk/view?usp=sharing)          
**InterSpeech 2024**  <span style="color:red">**(Oral)**</span>  

* [AV-RIR: Audio-Visual Room Impulse Response Estimation](https://arxiv.org/abs/2312.00834)  
Anton Ratnarajah, *Sreyan Ghosh*, Sonal Kumar, Purva Chiniya, Dinesh Manocha  
[Project Website](https://anton-jeran.github.io/AVRIR/) / [Poster](../assets/cvpr_2024_poster.pdf)  
**CVPR 2024**  

* [CompA: Addressing the Gap in Compositional Reasoning in Audio-Language Models](https://arxiv.org/abs/2310.08753)  
*Sreyan Ghosh*\*, Ashish Seth\*, Sonal Kumar\*, Utkarsh Tyagi\*, Chandra Kiran Reddy Evuru\*, Ramaneswaran S, S Sakshi, Oriol Nieto, Ramani Duraiswami, Dinesh Manocha  
[Project Webiste](https://sreyan88.github.io/compa_iclr/) / [Slides](../assets/ICLR_Presentation.pdf) / [Poster](../assets/iclr_poster.pdf)      
**ICLR 2024**  

* [RECAP: Retrieval-Augmented Audio Captioning](https://arxiv.org/abs/2309.09836)  
*Sreyan Ghosh*, Sonal Kumar, Chandra Kiran Reddy Evuru, Ramani Duraiswami, Dinesh Manocha   
[Code](https://github.com/Sreyan88/RECAP) / [Slides](https://docs.google.com/presentation/d/1F_mw2Viaj2hPrWAUIj8qmBk1DDakhYbJ/edit?usp=sharing&ouid=111957209895724121113&rtpof=true&sd=true)  
**ICASSP 2024**  <span style="color:red">**(Oral)**</span>  

* [Stable Distillation: Regularizing Continued Pre-training for Low-Resource Automatic Speech Recognition](https://arxiv.org/abs/2312.12783)  
Ashish Seth\*, *Sreyan Ghosh*\*, S. Umesh, Dinesh Manocha   
[Code](https://github.com/cs20s030/stable_distillation) / [Poster](../assets/icassp_stable_present.pdf)  
**ICASSP 2024** 

* [FusDom: Combining In-Domain and Out-of-Domain Knowledge for Continuous Self-Supervised Learning](https://arxiv.org/abs/2312.13026)  
Ashish Seth\*, *Sreyan Ghosh*\*, S. Umesh, Dinesh Manocha   
[Code](https://github.com/cs20s030/fusdom) / [Poster](../assets/icassp_fusdom_present.pdf)  
**ICASSP 2024**  

* [AdVerb: Visually Guided Audio Dereverberation](https://arxiv.org/abs/2308.12370)  
Sanjoy Chowdhury\*, *Sreyan Ghosh*\*, Subhrajyoti Dasgupta, Anton Ratnarajah, Utkarsh Tyagi, Dinesh Manocha  
[Poster](../assets/adverb_poster_ICCV.pdf)    
**ICCV 2023**  

* [MMER: Multimodal Multi-task Learning for Speech Emotion Recognition](http://arxiv.org/abs/2203.16794)  
*Sreyan Ghosh*, Utkarsh Tyagi, Ramaneswaran S, Harshvardhan Srivastava, Dinesh Manocha  
[Code](https://github.com/Sreyan88/MMER) / [Slides](https://docs.google.com/presentation/d/1aJzo0nKl1BGLmGikf7zdrHi_MhZSKpQm/edit?usp=sharing&ouid=111957209895724121113&rtpof=true&sd=true)  
**Interspeech 2023**  <span style="color:red">**(Oral)**</span>  

* [Decorrelating Feature Spaces for Learning General Purpose Audio Representations](https://ieeexplore.ieee.org/document/9868132)    
*Sreyan Ghosh*\*, Ashish Seth\*, S. Umesh    
[Code](https://github.com/Sreyan88/LAPE) / [Poster](../assets/delores_poster_final.pdf)   
**IEEE JSTSP Special Issue on Self-Supervised Learning for Speech and Audio Processing**  
**ICASSP 2023**  

* [data2vec-aqc: Search for the right Teaching Assistant in the Teacher-Student training setup](https://arxiv.org/abs/2211.01246)  
Lodagala V S V Durga Prasad\*, *Sreyan Ghosh*\*, S. Umesh  
[Code](https://github.com/Speech-Lab-IITM/data2vec-aqc) / [Leaderboard](https://superbbenchmark.org/leaderboard?subset=Public+Set)  
**ICASSP 2023**  <span style="color:red">**(Oral)**</span>  

* [MAST: Multiscale Audio Spectrogram Transformers](http://arxiv.org/abs/2211.01515)  
*Sreyan Ghosh*\*, Ashish Seth\*, S. Umesh, Dinesh Manocha  
[Code](https://github.com/Sreyan88/LAPE) / [Poster](../assets/mast_poster_final.pdf)  
**ICASSP 2023**  

* [SLICER: Learning universal audio representations using low-resource self-supervised pre-training](http://arxiv.org/abs/2211.01519)  
Ashish Seth\*, *Sreyan Ghosh*\*, S. Umesh, Dinesh Manocha  
[Code](https://github.com/Sreyan88/LAPE) / [Poster](../assets/slicer_poster_final.pdf)  
**ICASSP 2023**  

* [PADA: Pruning Assisted Domain Adaptation for Self-Supervised Speech Representations](http://arxiv.org/abs/2203.16965)   
Lodagala V S V Durga Prasad, *Sreyan Ghosh*, S. Umesh  
[Code](https://github.com/Speech-Lab-IITM/PADA)  
**IEEE SLT 2022**  

* [CCC-WAV2VEC 2.0: Clustering aided cross contrastive self-supervised learning of speech representations](http://arxiv.org/abs/2210.02592)   
Lodagala V S V Durga Prasad, *Sreyan Ghosh*, S. Umesh  
[Code](https://github.com/Speech-Lab-IITM/CCC-wav2vec-2.0) / [Leaderboard](https://superbbenchmark.org/leaderboard?subset=Public+Set)  
**IEEE SLT 2022**  

* [Span Classification with Structured Information for Disfluency Detection in Spoken Utterances](http://arxiv.org/abs/2203.16028)  
*Sreyan Ghosh*, Sonal Kumar, Yaman Kumar Singla, Rajiv Ratn Shah, S. Umesh  
[Code](https://github.com/Sreyan88/Disfluency-Detection-with-Span-Classification)  
**Interspeech 2022**  <span style="color:red">**(Oral)**</span>  

* [DeToxy: A Large-Scale Multimodal Dataset for Toxicity Classification in Spoken Utterances](https://arxiv.org/pdf/2110.07592.pdf)  
*Sreyan Ghosh*, Samden Lepcha, Sakshi, Rajiv Ratn Shah, S. Umesh  
[Code](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances) / [Data](https://github.com/Sreyan88/Toxicity-Detection-in-Spoken-Utterances/tree/main/data)  
**Interspeech 2022**  

* [End-to-end Named Entity Recognition from English Speech](https://www.isca-speech.org/archive_v0/Interspeech_2020/pdfs/2482.pdf)  
Hemant Yadav, *Sreyan Ghosh*, Yi Yu, Rajiv Ratn Shah  
[Code](https://github.com/raotnameh/End-to-end-E2E-Named-Entity-Recognition-from-English-Speech) / [Data](https://zenodo.org/record/3893954)  
**Interspeech 2020**  

### Natural Language Processing (Chronological)  

* [Visual Description Grounding Reduces Hallucinations and Boosts Reasoning in LVLMs](https://openreview.net/forum?id=3PRvlT8b1R)    
*Sreyan Ghosh*\*, Chandra Kiran Reddy Evuru\*, Sonal Kumar\*, Utkarsh Tyagi, Oriol Nieto, Zeyu Jin, Dinesh Manocha  
[Project](https://sreyan88.github.io/VDGD/)  / [Slides](https://docs.google.com/presentation/d/1dvCKLu_WBvKQFnvx7ZigtdPivK7o1RGn/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true) / [Summary Tweet](https://x.com/SreyanG/status/1795113972212867525)  
**ICLR 2025**  

* [ABEX: Data Augmentation for Low-Resource NLU via Expanding Abstract Descriptions](https://arxiv.org/abs/2406.04286)  
*Sreyan Ghosh*\*, Utkarsh Tyagi\*, Sonal Kumar, Chandra Kiran Reddy Evuru, Ramaneswaran S, S. Sakshi, Dinesh Manocha  
[Code](https://github.com/Sreyan88/ABEX)  /  [Poster](../assets/ACL-ABEX.pdf)  
**ACL 2024**  

* [ASPIRE: Language-Guided Augmentation for Robust Image Classification](https://arxiv.org/abs/2308.10103)  
*Sreyan Ghosh*\*, Chandra Kiran Reddy Evuru\*, Sonal Kumar\*, S. Sakshi, Utkarsh Tyagi, Dinesh Manocha  
[Code](https://github.com/Sreyan88/ASPIRE)  / [Slides](https://docs.google.com/presentation/d/1x7mI9lOF2dGQx1OQe6nk9a53clhTxeD_/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true) / [Talk](https://drive.google.com/file/d/1QCkH1MwYthlVtoRtGUTRZJ19YGBZvDZy/view?usp=sharing) / [Poster](../assets/ACL-ASPIRE.pdf)  
**ACL 2024 Findings**  

* [A Closer Look at the Limitations of Instruction Tuning](https://arxiv.org/abs/2402.05119)    
*Sreyan Ghosh*\*, Chandra Kiran Reddy Evuru\*, Sonal Kumar\*, Ramaneswaran S, Deepali Aneja, Zeyu Jin, Ramani Duraiswami, Dinesh Manocha  
[Summary Tweet](https://x.com/SreyanG/status/1755957189506638125) / [Poster](../assets/ICML_poster_closer.pdf)  / [Slides](https://docs.google.com/presentation/d/1ae1f5Mqby_Nsxyvv9QzF2-nnrpA-1-Fb/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true) / [Video](https://www.youtube.com/watch?v=sW_G1FQ86pQ)   
**ICML 2024**  

* [Do Vision-Language Models Understand Compound Nouns?](https://arxiv.org/abs/2404.00419)  
Sonal Kumar\*, *Sreyan Ghosh*\*, S Sakshi, Utkarsh Tyagi, Dinesh Manocha    
[Code](https://github.com/sonalkum/Compun) / [Slides](https://docs.google.com/presentation/d/1HT88DhFeA3fwTW0MGCkBA_ZaJxlQqmx0/edit?usp=sharing&ouid=106741382757375410342&rtpof=true&sd=true) / [Talk](https://drive.google.com/file/d/1w2ytAD5zK9s8fmnvhvceEgWO_g19eBrF/view?usp=sharing) / [Poster](../assets/compun_naacl_poster.pdf)    
**NAACL 2024**  

* [CoDa: Constrained Generation based Data Augmentation for Low-Resource NLP](https://arxiv.org/abs/2404.00415)  
Chandra Kiran Reddy Evuru\*, *Sreyan Ghosh*\*, Sonal Kumar, Ramaneswaran S, Utkarsh Tyagi, Dinesh Manocha   
[Code](https://github.com/Sreyan88/CoDa) / [Talk](https://drive.google.com/file/d/1WtgRNjle5W2GwImKjm-ZibZXY8xC9o6B/view?usp=sharing) / [Poster](../assets/coda_poster.pdf)  
**NAACL 2024 Findings**  

* [DALE: Generative Data Augmentation for Low-Resource Legal NLP](https://arxiv.org/abs/2310.15799)    
*Sreyan Ghosh*\*, Chandra Kiran Reddy Evuru\*, Sonal Kumar, Ramaneswaran S, S Sakshi, Utkarsh Tyagi, Dinesh Manocha  
[Code](https://github.com/Sreyan88/DALE) / [Poster](../assets/DALE_poster_EMNLP.pdf)  
**EMNLP 2023**  

* [CoSyn: Detecting Implicit Hate Speech in Online Conversations Using a Context Synergized Hyperbolic Network](http://arxiv.org/abs/2303.03387)   
*Sreyan Ghosh*\*, Manan Suri\*, Purva Chiniya\*, Utkarsh Tyagi\*, Sonal Kumar\*, Dinesh Manocha  
[Code](https://github.com/Sreyan88/CoSyn) / [Poster](../assets/CoSyn_poster_EMNLP.pdf)  
**EMNLP 2023**  

* [ACLM: A Selective-Denoising based Generative Data Augmentation Approach for Low-Resource Complex NER](https://arxiv.org/abs/2306.00928v1)  
*Sreyan Ghosh*\*, Utkarsh Tyagi\*, Manan Suri, Sonal Kumar, Ramaneswaran S, Dinesh Manocha  
[Code](https://github.com/Sreyan88/ACLM) / [Poster](../assets/acl_final_poster.pdf)  
**ACL 2023**  

* [BioAug: Conditional Generation based Data Augmentation for Low-Resource Biomedical NER](https://arxiv.org/abs/2305.10647)  
*Sreyan Ghosh*\*, Utkarsh Tyagi\*, Sonal Kumar\*, Dinesh Manocha  
[Code](https://github.com/Sreyan88/BioAug) / [Poster](../assets/SIGIR_FINAL.pdf)   
**SIGIR 2023**  

### Workshop

* [UNFUSED: UNsupervised Finetuning Using SElf supervised Distillation](https://arxiv.org/abs/2303.05668)  
Ashish Seth\*, Sreyan Ghosh\*, S. Umesh, Dinesh Manocha  
[Code](https://github.com/Sreyan88/LAPE) / [Poster](../assets/unfused_final.pdf)  
**ICASSP 2023 SASB Workshop**  

* [DeLoRes: Decorrelating Latent Spaces for Low-Resource Audio Representation Learning](https://arxiv.org/abs/2203.13628)   
*Sreyan Ghosh*, Ashish Seth, Deepak Mittal, Maneesh Singh, S. Umesh   
[Code](https://github.com/Speech-Lab-IITM/DeLoRes)  
**SAS Workshop @ AAAI 2022**    

* [Leveraging Transformers for Hate Speech Detection in Conversational Code-Mixed Tweets](https://arxiv.org/pdf/2112.09986.pdf)    
Zaki Mustafa Farooqi, *Sreyan Ghosh*, Rajiv Ratn Shah  
[Leader Board (Team Name: MIDAS@IIIT-D)](https://hasocfire.github.io/hasoc/2021/results.html#)  
**FIRE 2021**  

* [Cisco at SemEval-2021 Task 5: What's Toxic?: Leveraging Transformers for Multiple Toxic Span Extraction from Online Comments](https://aclanthology.org/2021.semeval-1.29.pdf)  
*Sreyan Ghosh*, Sonal Kumar  
[Code](https://github.com/Sreyan88/SemEval-2021-Toxic-Spans-Detection)  
**SemEval-2021 @ ACL 2021**  

* [Cisco at AAAI-CAD21 shared task: Predicting Emphasis in Presentation Slides using Contextualized Embeddings](https://arxiv.org/pdf/2101.11422.pdf)   
*Sreyan Ghosh*, Sonal Kumar, Harsh Jalan, Hemant Yadav, Rajiv Ratn Shah  
[Code](https://github.com/Sreyan88/CAD21-AAAI21)  
**CAD-21 @ AAAI 2021**  
