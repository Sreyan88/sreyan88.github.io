---
layout: page
---
{% include JB/setup %}

<img style="float: right; width: 35%; padding: 6px;" src=" {{ site.url }}assets/IMG_7210.jpg">

I am Sreyan Ghosh. I am currently a 3rd year C.S. Ph.D. student at the University of Maryland, College Park (UMCP). At UMCP, I work under the guidance of [Prof. Dinesh Manocha](https://scholar.google.com/citations?user=X08l_4IAAAAJ&hl=en) at [Gamma Lab](https://gamma.umd.edu/) on *resource-efficient deep learning*. I apply my research to various problems in speech, language and audio processing.  

Previously, I served as a Deep Learning Solutions Architect at [Nvidia, Bangalore](https://www.nvidia.com/en-in/). My primary work at Nvidia involved building and delivering deep learning based NLP solutions to Nvidia's customers and partners. Previous to that, I served as a Software Engineer II at [Cisco Systems, Bangalore](http://cisco.com). My primary work at Cisco involved building network assurance software systems for Cisco's Service Provider customers.  

I have been fortunate to have worked with [Prof. S. Umesh](http://www.ee.iitm.ac.in/~umeshs/) at [Speech Lab @ Indian Institute of Technology Madras](https://www.iitm.ac.in/speech/lab/) on making self-supervised learning in speech and audio more amenable to resource-constrained scenarios (both data and compute). I have also worked with [Prof. Rajiv Ratn Shah](https://www.iiitd.ac.in/rajivratn) at [MIDAS Labs @ IIIT Delhi](http://midas.iiitd.edu.in/) on content moderation, complex named entity recognition and speech recognition systems for low-resource Indian languages and Indian-accented English.

I graduated with a Bachelor's in Computer Science and Engineering from [Christ University](https://christuniversity.in/) in 2020. During my undergraduate studies, I served as the Vice President and co-founder of Neuron, Christ University's first AI group focused on research and hackathons. During my undergraduate studies, I have won over 20 national and international hackathons.

I maintain a list of my publications and research implementations under the [Research]({{ site.url }}/research) tab. I also [blog]({{ site.url }}/archive) about my personal experiences and topics related to speech and text processing. I am always open to collaborations, and please feel free to drop me a mail!

CV / Resume: [link]({{ site.url }}/assets/Sreyan_Ghosh_CV.pdf)  
Email ID: [gsreyan@gmail.com](mailto:gsreyan@gmail.com) ; [sreyang@umd.edu](mailto:sreyang@umd.edu)  

ðŸ“£ We announce the first [Call for Papers](https://salmaworkshop.github.io/call/index.html) for the [Workshop on Speech and Audio Language Models (SALMA)](https://salmaworkshop.github.io/), co-located with [ICASSP 2025](https://2025.ieeeicassp.org/) in Hyderabad, India! ðŸ“£

<!-- #### I am always open to collaborations! Please fill out [this](https://docs.google.com/forms/d/1kQRJekonn8YglxIPH9OPcJCuI7NQK-E1wAywNAsSMoM/) form here and I would reach out if I have a project aligned with your interests. Thank You! -->

#### Updates

<div style="height:275px;overflow:auto;">
<table>
<col width="100px">
<col width="630px">
  <tr><td><b>Sept 2024:</b></td><td>We released MMAU, the most comprehesive audio understanding and reasoning benchmark yet! Check it out here: https://sakshi113.github.io/mmau_homepage/ ! </td></tr>
  <tr><td><b>Sept 2024:</b></td><td>2 papers accepted to EMNLP 2024!</td></tr>
  <tr><td><b>Aug 2024:</b></td><td>Our workshop proposal, SALMA, has been accepted to ICASSP 2025!</td></tr>
  <tr><td><b>June 2024:</b></td><td>We release GAMA, an LLM with strong audio-understanding capabilities! Details under the Research section.</td></tr>
  <tr><td><b>May 2024:</b></td><td>1 paper accepted to InterSpeech 2024!</td></tr>
  <tr><td><b>May 2024:</b></td><td>Joined Microsoft in Redmond as a Research Scientist Intern!</td></tr>
  <tr><td><b>May 2024:</b></td><td>2 papers accepted to ACL 2024!</td></tr>
  <tr><td><b>May 2024:</b></td><td>1 paper accepted to ICML 2024!</td></tr>
  <tr><td><b>March 2024:</b></td><td>2 papers accepted to NAACL 2024!</td></tr>
  <tr><td><b>Feb 2024:</b></td><td>1 paper accepted to CVPR 2024!</td></tr>
  <tr><td><b>Jan 2024:</b></td><td>1 paper accepted to ICLR 2024!</td></tr>
  <tr><td><b>Dec 2023:</b></td><td>Awarded the UMD graduate school's Outstanding RA Award!</td></tr>
  <tr><td><b>Dec 2023:</b></td><td>3 papers accepted to ICASSP 2024! Details under the research section.</td></tr>
  <tr><td><b>Dec 2023:</b></td><td>Attended EMNLP 2023 in-person in Singapore!</td></tr>
  <tr><td><b>Oct 2023:</b></td><td>2 papers accepted to EMNLP 2023! Details under the research section.</td></tr>
  <tr><td><b>Oct 2023:</b></td><td>Attended ICCV 2023 in-person in Paris!</td></tr>
  <tr><td><b>Oct 2023:</b></td><td>Attended InterSpeech 2023 in-person in Dublin!</td></tr>
  <tr><td><b>May 2023:</b></td><td>Our paper was accepted to ICCV 2023!</td></tr>
  <tr><td><b>May 2023:</b></td><td>Started as a Research Scientist Intern at Adobe Research!</td></tr>
  <tr><td><b>May 2023:</b></td><td>Our paper was accepted to Interspeech 2023!</td></tr>
  <tr><td><b>Apr 2023:</b></td><td>Our paper was accepted to ACL 2023!</td></tr>
  <tr><td><b>Apr 2023:</b></td><td>Our paper was accepted to SIGIR 2023!</td></tr>
  <tr><td><b>Mar 2023:</b></td><td>Serving as a reviewer for Interspeech 2023!</td></tr>
  <tr><td><b>Feb 2023:</b></td><td>I got admitted to the C.S. Ph.D. program at UMD! I will be starting in the Fall of 2023!.</td></tr>
  <tr><td><b>Feb 2023:</b></td><td>3 papers accepted to ICASSP 2023! Pre-prints under the research section.</td></tr>
  <tr><td><b>Feb 2023:</b></td><td>Serving as a reviewer for ACL 2023!</td></tr>
  <tr><td><b>Jan 2023:</b></td><td>Submitted one paper to ACL 2023!</td></tr>
  <tr><td><b>Jan 2023:</b></td><td>Our team <em>Shravan</em> won the <em>Best Demo Implementation award</em> at the 2022 IEEE-SLT Code Hackathon! Links to slides and recording of the presentation to be posted soon under the Others tab.</td></tr>
  <tr><td><b>Jan 2023:</b></td><td>Served as a reviewer for AAAI 2023 Muffin Workshop.</td></tr>
  <tr><td><b>Dec 2022:</b></td><td>Served as a reviewer for ICASSP 2023.</td></tr>
  <tr><td><b>Nov 2022:</b></td><td>Served as a reviewer for AAAI 2023.</td></tr>
  <tr><td><b>Oct 2022:</b></td><td>4 papers submitted to IEEE ICASSP 2023! Pre-print and codes to be made available soon!</td></tr>
  <tr><td><b>Sept 2022:</b></td><td>2 papers accepted to IEEE SLT 2022! Pre-print and code now available!</td></tr>
  <tr><td><b>Aug 2022:</b></td><td>Paper on low-resource audio representation learning accepted to IEEE JSTSP Special Issue! More details under the research section!</td></tr>
  <tr><td><b>Aug 2022:</b></td><td>Moved to the beautiful city of College Park and started school at the University of Maryland!</td></tr>
  <tr><td><b>July 2022:</b></td><td>Started contributing to GSoC 2022 for the Keras Organization. More details about my project can be found in the Projects section!</td></tr>
  <tr><td><b>July 2022:</b></td><td>2 papers accepted to Interspeech 2022! Pre-print and codes now available now!</td></tr>  
  <tr><td><b>Dec 2021:</b></td><td>Paper on Low-Resource Audio Representation Learning accepted to AAAI 2022 SAS Workshop! Pre-print now available under research section!</td></tr>