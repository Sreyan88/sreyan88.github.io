---
layout: page
---
{% include JB/setup %}

<img style="float: right; width: 35%; padding: 6px;" src=" {{ site.url }}assets/IMG_7210.jpg">

I am Sreyan Ghosh, a 3rd-year Computer Science Ph.D. student at the University of Maryland, College Park (UMD). I conduct my research in the [Gamma Lab](https://gamma.umd.edu/) under the mentorship of [Prof. Dinesh Manocha](https://scholar.google.com/citations?user=X08l_4IAAAAJ&hl=en). My work focuses on advancing *audio processing*â€”spanning speech, sounds, and music. I aim to tackle challenges such as developing data- and compute-efficient audio models, improving audio representation learning, and enhancing audio perception and reasoning in AI systems. My research is proudly supported by the [NVIDIA Graduate Fellowship](http://go.umd.edu/Ghosh).    

Previously, I served as a Deep Learning Solutions Architect at [Nvidia, Bangalore](https://www.nvidia.com/en-in/). My primary work at Nvidia involved building and delivering deep learning based NLP solutions to Nvidia's customers and partners. Previous to that, I served as a Software Engineer II at [Cisco Systems, Bangalore](http://cisco.com). My primary work at Cisco involved building network assurance software systems for Cisco's Service Provider customers.  

I have been fortunate to have worked with [Prof. S. Umesh](http://www.ee.iitm.ac.in/~umeshs/) at [Speech Lab @ Indian Institute of Technology Madras](https://www.iitm.ac.in/speech/lab/) on making self-supervised learning in speech and audio more amenable to resource-constrained scenarios (both data and compute). I have also worked with [Prof. Rajiv Ratn Shah](https://www.iiitd.ac.in/rajivratn) at [MIDAS Labs @ IIIT Delhi](http://midas.iiitd.edu.in/) on content moderation, complex named entity recognition and speech recognition systems for low-resource Indian languages and Indian-accented English.

I graduated with a Bachelor's in Computer Science and Engineering from [Christ University](https://christuniversity.in/) in 2020. During my undergraduate studies, I served as the Vice President and co-founder of Neuron, Christ University's first AI group focused on research and hackathons. During my undergraduate studies, I have won over 20 national and international hackathons.

I maintain a list of my publications and research implementations under the [Research]({{ site.url }}/research) tab. I also [blog]({{ site.url }}/archive) about my personal experiences and topics related to speech and text processing. I am always open to collaborations, and please feel free to drop me a mail!

CV / Resume: [link]({{ site.url }}/assets/Sreyan_Ghosh_CV.pdf)  
Email ID: [gsreyan@gmail.com](mailto:gsreyan@gmail.com) ; [sreyang@umd.edu](mailto:sreyang@umd.edu)  

ðŸ“£ We announce the first [Call for Papers](https://salmaworkshop.github.io/call/index.html) for the [Workshop on Speech and Audio Language Models (SALMA)](https://salmaworkshop.github.io/), co-located with [ICASSP 2025](https://2025.ieeeicassp.org/) in Hyderabad, India! ðŸ“£

<!-- #### I am always open to collaborations! Please fill out [this](https://docs.google.com/forms/d/1kQRJekonn8YglxIPH9OPcJCuI7NQK-E1wAywNAsSMoM/) form here and I would reach out if I have a project aligned with your interests. Thank You! -->

#### Updates

<div style="height:275px;overflow:auto;">
<table>
<col width="100px">
<col width="630px">
  <tr><td><b>Mar 2025:</b></td><td>We release <a href="https://arxiv.org/abs/2503.03983" target="_blank">Audio Flamingo 2</a>, a SOTA audio-language model outperforming most other frontier models on audio understanding and reasoning tasks. Check out the <a href="https://huggingface.co/spaces/nvidia/audio-flamingo-2" target="_blank">demo</a> here!</td></tr>
  <tr><td><b>Jan 2025:</b></td><td><a href="https://openreview.net/forum?id=3PRvlT8b1R" target="_blank">VDGD</a>, <a href="https://openreview.net/forum?id=TeVAZXr3yv" target="_blank">MMAU</a> (Spotlight) and <a href="https://openreview.net/forum?id=bR1J7SpzrD" target="_blank">Synthio</a> have been accepted to ICLR 2025! More details under the Research section.</td></tr>
  <tr><td><b>Jan 2025:</b></td><td><a href="https://arxiv.org/abs/2410.15062" target="_blank">PAT</a>, <a href="https://arxiv.org/pdf/2410.16505" target="_blank">RobustCLAP</a> and ProSE have been accepted to NAACL 2025! More details under the Research section.</td></tr>
    <tr><td><b>Dec 2024:</b></td><td><a href="https://arxiv.org/abs/2409.09213" target="_blank">ReCLAP</a> (and a total of 3 papers) have been accepted to ICASSP 2025! More details under the Research section.</td></tr>
  <tr><td><b>Dec 2024:</b></td><td>We are hosting the DCASE 2025 Task 5 in collaboration with NVIDIA! More details <a href="https://dcase.community/articles/challenge-tasks-for-dcase2025" target="_blank">here</a>.</td></tr>
  <tr><td><b>Nov 2024:</b></td><td>I was awarded the <a href="https://www.cs.umd.edu/article/2024/12/umd-cs-phd-student-receives-nvidia-graduate-fellowship%C2%A0" target="_blank">NVIDIA</a> and Apple graduate fellowships! I have decided to accept the NVIDIA fellowship.</td></tr>
  <tr><td><b>Sept 2024:</b></td><td>We released <a href="https://sakshi113.github.io/mmau_homepage/" target="_blank">MMAU</a>, the most comprehesive audio understanding and reasoning benchmark yet!</td></tr>
  <tr><td><b>Sept 2024:</b></td><td>2 papers accepted to EMNLP 2024 as oral presentations!</td></tr>
  <tr><td><b>Aug 2024:</b></td><td>Our workshop proposal, SALMA, has been accepted to ICASSP 2025!</td></tr>
  <tr><td><b>June 2024:</b></td><td>We release GAMA, an LLM with strong audio-understanding capabilities! Details under the Research section.</td></tr>
  <tr><td><b>May 2024:</b></td><td>1 paper accepted to InterSpeech 2024!</td></tr>
  <tr><td><b>May 2024:</b></td><td>Joined Microsoft in Redmond as a Research Scientist Intern!</td></tr>
  <tr><td><b>May 2024:</b></td><td>2 papers accepted to ACL 2024!</td></tr>
  <tr><td><b>May 2024:</b></td><td>1 paper accepted to ICML 2024!</td></tr>
  <tr><td><b>March 2024:</b></td><td>2 papers accepted to NAACL 2024!</td></tr>
  <tr><td><b>Feb 2024:</b></td><td>1 paper accepted to CVPR 2024!</td></tr>
  <tr><td><b>Jan 2024:</b></td><td>1 paper accepted to ICLR 2024!</td></tr>
  <tr><td><b>Dec 2023:</b></td><td>Awarded the UMD graduate school's Outstanding RA Award!</td></tr>
  <tr><td><b>Dec 2023:</b></td><td>3 papers accepted to ICASSP 2024! Details under the research section.</td></tr>
  <tr><td><b>Dec 2023:</b></td><td>Attended EMNLP 2023 in-person in Singapore!</td></tr>
  <tr><td><b>Oct 2023:</b></td><td>2 papers accepted to EMNLP 2023! Details under the research section.</td></tr>
  <tr><td><b>Oct 2023:</b></td><td>Attended ICCV 2023 in-person in Paris!</td></tr>
  <tr><td><b>Oct 2023:</b></td><td>Attended InterSpeech 2023 in-person in Dublin!</td></tr>
  <tr><td><b>May 2023:</b></td><td>Our paper was accepted to ICCV 2023!</td></tr>
  <tr><td><b>May 2023:</b></td><td>Started as a Research Scientist Intern at Adobe Research!</td></tr>
  <tr><td><b>May 2023:</b></td><td>Our paper was accepted to Interspeech 2023!</td></tr>
  <tr><td><b>Apr 2023:</b></td><td>Our paper was accepted to ACL 2023!</td></tr>
  <tr><td><b>Apr 2023:</b></td><td>Our paper was accepted to SIGIR 2023!</td></tr>
  <tr><td><b>Mar 2023:</b></td><td>Serving as a reviewer for Interspeech 2023!</td></tr>
  <tr><td><b>Feb 2023:</b></td><td>I got admitted to the C.S. Ph.D. program at UMD! I will be starting in the Fall of 2023!.</td></tr>
  <tr><td><b>Feb 2023:</b></td><td>3 papers accepted to ICASSP 2023! Pre-prints under the research section.</td></tr>
  <tr><td><b>Feb 2023:</b></td><td>Serving as a reviewer for ACL 2023!</td></tr>
  <tr><td><b>Jan 2023:</b></td><td>Submitted one paper to ACL 2023!</td></tr>
  <tr><td><b>Jan 2023:</b></td><td>Our team <em>Shravan</em> won the <em>Best Demo Implementation award</em> at the 2022 IEEE-SLT Code Hackathon! Links to slides and recording of the presentation to be posted soon under the Others tab.</td></tr>
  <tr><td><b>Jan 2023:</b></td><td>Served as a reviewer for AAAI 2023 Muffin Workshop.</td></tr>
  <tr><td><b>Dec 2022:</b></td><td>Served as a reviewer for ICASSP 2023.</td></tr>
  <tr><td><b>Nov 2022:</b></td><td>Served as a reviewer for AAAI 2023.</td></tr>
  <tr><td><b>Oct 2022:</b></td><td>4 papers submitted to IEEE ICASSP 2023! Pre-print and codes to be made available soon!</td></tr>
  <tr><td><b>Sept 2022:</b></td><td>2 papers accepted to IEEE SLT 2022! Pre-print and code now available!</td></tr>
  <tr><td><b>Aug 2022:</b></td><td>Paper on low-resource audio representation learning accepted to IEEE JSTSP Special Issue! More details under the research section!</td></tr>
  <tr><td><b>Aug 2022:</b></td><td>Moved to the beautiful city of College Park and started school at the University of Maryland!</td></tr>
  <tr><td><b>July 2022:</b></td><td>Started contributing to GSoC 2022 for the Keras Organization. More details about my project can be found in the Projects section!</td></tr>
  <tr><td><b>July 2022:</b></td><td>2 papers accepted to Interspeech 2022! Pre-print and codes now available now!</td></tr>  
  <tr><td><b>Dec 2021:</b></td><td>Paper on Low-Resource Audio Representation Learning accepted to AAAI 2022 SAS Workshop! Pre-print now available under research section!</td></tr>